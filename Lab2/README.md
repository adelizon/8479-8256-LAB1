# _ΕΡΓΑΣΤΗΡΙΑΚΗ ΑΣΚΗΣΗ 2_

## ΟΜΑΔΑ 41
ΔΕΛΗΖΩΝΑΣ ΑΠΟΣΤΟΛΟΣ ΑΕΜ: 8479

ΤΣΙΑΝΤΟΣ ΑΠΟΣΤΟΛΟΣ ΑΕΜ: 8256


## Μέρος 1ο
### Ερώτημα 1ο:
  
Βρίσκουμε από το αρχείο _CONFIG.INI_ του εκάστοτε benchmark, πως το _**cache line size**_ είναι 64 bytes.

Για τις _dcache, icache, l2cache_ παρατίθεται ο παρακάτω πίνακας.

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/1o%20er.png)


### Ερώτημα 2ο:

Για να αντλήσουμε τις πληροφιρίες που ζητούνται στο ερώτημα 2, θα ανατρέξουμε στα αρχεία _stats.txt_ των benchmarks. Ο παρακάτω πίνακας παρουσιάζει συνολικά τα _**miss rates**_ των caches, τα _**CPI**_ καθώς και τους χρόνους εκτέλεσης του κάθε benchmark:

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/2o%20erwt.png)

Στη συνέχεια παραθέτονται ορισμένα διαγράμματα σχετικά με τα στατιστικά αυτά, για το σύνολο των benchmarks.


![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/L1D.png)


![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/L1I.png)


![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/L2.png)


![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/CPI.png)


![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/SIM%20TIME.png)


#### Συμπεράσματα:
Από τα διαγράμματα που παρουσιάστηκαν παραπάνω, μπορούμε να αντλήσουμε ορισμένα χρήσιμα συμπεράσματα.
Ξεκινώντας απ το **miss rate** της **instruction cache**, μπορούμε να δούμε πως είναι πολύ χαμήλό για το σύνολο των benchmarks, με αποτέλεσμα να μην επηρεάζει τη ταχύτητα τους, ακόμα και για τη περίπτωση του _**specmcf**_, όπου είναι αρκετά υψηλότερο από τα υπόλοιπα, αλλά σε χαμηλή τιμη.

Συνεχίζοντας με το **miss rate** της **l2 cache**, βλέπουμε ξεκάθαρα πως για τα benchmarks _**speclibm & specsjeng**_ ο αριθμός αυτός τείνει στο 1, γεγονός που σημαίνει πως σχεδόν σε κάθε αναζήτηση της l2 υπάρχει miss, πράγμα που σημαίνει πως θα πρέπει να ελεγχθεί η κύρια μνήμη, η οποία είναι και πολύ πιο αργή από τις caches. Αυτό αποτυπώνεται και στους χρόνουν εκτέλεσης, όπου τα δύο benchmarks αυτά είναι τα πιο χρονοβόρα.

Ωστόσο η μεγάλη διαφορά μεταξύ αυτών των δύο, έγκειται στο **miss rate** της **l1 data cache**, το οποίο είναι σχεδόν διπλάσιο στον specsjeng, το οποίο με τη σειρά του οδηγεί σε αρκετά μεγαλύτερο χρόνο εκτέλεσης.

Τέλος, το διάγραμμα των _**CPI**_, το οποίο στην ουσία αποτυπώνει το πόσο γρήγορο είναι το σύστημά μας, επιβεβαιώνεται από το πραγματικό διάγραμμα των χρόνων εκτέλεσης.


### Ερώτημα 3ο:
Για το ερώτημα αυτό, επιλέγουμε να τρέξουμε σε συχνότητα επεξεργαστή στο 1GHz, τα benchmarks _**specbzip, specmcf & specsjeng**_.

Παρατηρούμε μέσα από το αρχείο stats.txt, πως ενώ η συχνότητα του επεξεργαστή όντως αλλάζει και από 2GHz γίνεται 1GHz, ωστόσο η συχνότητα του συστήματος (system clk domain) παραμένει σταθερά στο 1GHz. Αυτή η μεταβλητή, αναφέρεται στη συχνότητα όλου του συστήματος, πρακτικά τη συνχότητα με την οποία επικοινωνεί ο επεξεργαστής με τα υπόλοιπα υποσυστήματα (μνήμες κτλ).

Συνεπώς μπορούμε να αντιληφθούμε πως ο υποδιπλασιασμός της συχνότητας του επεξεργαστεί μπορεί να αποφέρει διπλασιασμό του χρόνου εκτέλεσης του benchmark, ωστόσο αυτό δεν είναι απαραίτητο καθώς η καθυστέρηση μπορεί να μην έγκειται μόνο στη συχνότητα που εκτελεί ο επεξεργαστής της διεργασίες του, αλλά και στην επικοινωνία που έχει με τα υπόλοιπα υποσυστήματα. Παρακάτω παρουσιάζονται τα αποτελέσματα που προέκυψαν από τα 3 διαφορετικά benchmarks που τρέξαμε στο 1GHz, σε σχέση με αυτά των 2GHz:

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/3o.png)

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/1ghz.png)

Στα benchmarks specbzip και specmcf υπάρχει σχεδόν τέλειο scaling με το χρόνο εκτέλεσης να διπλασιάζεται για υποδιπλασιασμό της συχνότητας του επεξεργαστή, πράγμα που δε συμβαίνει και στο specsjeng, για το λόγο που αναφέραμε παραπάνω.


## Μέρος 2ο

Στο δεύτερο μέρος της εργαστηριακής άσκησης, θα παρουσιάσουμε αποτελέσματα των benchmarks _**specbzip, speclibm, specsjeng**_.

Για το σύνολο αυτών, παρατηρήθηκε πως αλλαγές στο μέγεθος και το associativity της icache δεν απέφεραν καμία αλλαγή στα CPI των benchmarks, γι αυτό και δεν παρουσιάζονται στα παρακάτω στοιχεία.

**Specsjeng**: Πρόκειται για το πιο χρονοβόρο benchmark της εργασίας, με τη τιμή του CPI να είναι μεγαλύτερη από 10, και το χρόνο εκτέλεσης κοντά στα 0.5 δευτερόλεπτα. Παρακάτω παρουσιάζονται τα στοιχεία και το αντίστοιχο γράφημα:

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/specsjeng1.png)

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/specsjeng%20plot.png)

Παρατηρήσεις: Αλλάζοντας μεγέθη και συσχετίσεις των διαφορετικών caches, μπορούμε να παρατηρήσουμε πως τόσο για την dcache, όσο και για την l2cache η αύξηση του μεγέθους της μνήμης τους και του associativity τους οδηγεί σε μείωση του CPI και συνεπώς του χρόνου εκτέλεσης. Παρόλα αυτά η διαφορά αυτή είναι αρκετά μικρή και πιθανώς μη υπολογίσιμη αφού και τα miss rates δεν εμφανίζουν κάποια διαφορά. Αλλάζοντας ωστόσο το μέγεθος του cacheline, παρατηρούμε μια μείωση της τάξης του 35% τόσο στο CPI όσο και στο χρόνο εκτέλεσης. Όπως παρατηρήθηκε και στο 1ο βήμα, η διαφορές αυτές ωφείλονται στη μεγάλη πτώση του miss rate της dcache. (_**φυσικά η τιμή έχει 128 για το cacheline size και 512 για associativity, καθώς και όλες οι υπόλοιπες τιμές, επιλέχθηκαν με βάση πραγματικ΄α΄ στοιχεία και με τους περιορισμούς που τέθηκαν από την εργασία).

**Speclibm**: Αποτελεί το δεύτερο πιο χρονοβόρο benchmark, με τιμή CPI περίπου 3.5 και χρόνο εκτέλεσης στα 0.17 δευτερόλεπτα. Παρακάτω παρουσιάζονται τα στοιχεία και το αντίστοιχο γράφημα:

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/speclibm.png)

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/speclibm%20plot.png)

Παρατηρήσεις: Ακολουθήσαμε την ίδια τακτική με το προηγούμενο benchmark, αυξάνοντας μεγέθη και συσχετίσεις στην dcache & l2cache. Σε αυτή τη περίπτωση ωστόσο μπορούμε να παρατηρήσουμε πως η αύξηση/μείωση μεγέθους και associativity στην dcache δεν επιφέρει καμία αλλαγή στη ταχύτητα του συστήματος. Αντίθετα η αύξηση/μείωση μεγέθους και associativity στην l2cache επιφέρει αντίστοιχα μείωση/αύξηση στο χρόνο εκτέλεσης, ωστόσο όπως και στο προηγούμενο benchmark η διαφορά είναι αρκετά μικρή. Τέλος, η αύξηση του cacheline size σε 128, είναι αυτή που επιφέρει ξανά τη μεγαλύτερη μείωση στο CPI του συστήματος, η οποία ανέρχεται στο 30%.

**Specbzip**: 

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/specbzip.png)

![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/specbzip%20plot.png)

Παρατηρήσεις: Στη περίπτωση αυτή παρατηρούμε πως η μεγαλύτερη διαφορά ωφείλεται στην αύξηση του associativity της dcache καθώς μειώνει περίπου κατα 30% το miss rate της dcache. Αντίστοιχα για μείωση του associativity της dcache έχουμε σχεδόν διπλασιασμό του miss rate και φυσικά αύξηση των CPI. Αυξάνοντας μέγεθος και συσχέτιση στην l2, καθώς και cacheline size, πετυχγαίνουμε ακόμα μεγαλύτερη βελτίωση η οποία ωστόσο θα μπορούσε να θεωρηθεί αμελητέα.

(_στα διάφορα benchmarks που τρέξαμε, κάθε ζεύγος τιμών dcache size, associativity που μας έδινε το καλύτερο αποτέλεσμα, διατηρούταν για τις διαφορετικές l2caches και αντίστοιχα για το cacheline size_)


## Μέρος 3ο

Κατασκευή συνάρτησης κόστους:

Θα προσπαθήσουμε τώρα, να δημιουργήσουμε μια συνάρτηση η οποία θα εκφράζει τη σχέση κόστους-αποδοτικότητας μιας αρχιτεκτονικής.
Μια τέτοια προσπάθεια αποτελεί πολύ βασική ενέργεια στην αρχιτεκτονική υπολογιστών, καθώς θέτει όρια και προδιαγραφές στους αρχιτέκτονες υπολογιστών. Όπως φάνηκε και από τις διάφορα benchmarks που τρέξαμε για το 2ο Μέρος, αν για παράδειγμα συνεχίζαμε να αυξάνουμε το μέγεθος του **cacheline size** η το **associativity των l1,l2**, θα είχαμε ακόμα περισσότερη μείωση στα CPI και συνεπώς αύξηση της αποδοτικότητας του συστήματος. Παρόλα αυτά, η αύξηση του μεγέθους μιας μνήμης, η αύξηση των συγκρίσεων άρα και λογικών πυλών που χρειάζονται για την υλοποίηση τους, καθώς και ο τύπος της μνήμης, επηρεάζουν σε μεγάλο βαθμό το κόστος ενός επεξεργαστή. Για αυτό το λόγο είναι απαραίτητη η κατασκευή τέτοιων συναρτήσεων, η οποίες θα συσχετίζουν κόστος και αποδοτικότητα, ανάλογα φυσικά με τις απαιτήσεις τις εφαρμογής.

Θα ξεκινήσουμε σχετίζοντας το κόστος της l1cache, l2cache. Ανατρέχοντας στη βιβλιογραφία καθώς και αντλώντας πληροφορίες από πραγματικές τιμές επεξεργαστών (σε μεγάλες ποσότητες φυσικά καθώς η διαφορά στη τιμή 2 μόνο επεξεργαστών δεν μπορεί να είναι αντιπροσωπευτική για μια εταιρία που κατασκευάζει επεξεργαστές), καταλήγουμε σε μια συσχέτιση 1:4. 
Θεωρώντας λοιπόν το κόστος της l1chache = Pl1, προκύπτει πως _**Pl1 = 4*Pl2_**.

Παράλληλα θα θεωρήσουμε μια αυθαίρετη τιμή _**1ic/kB**_, για να αποτυπώσουμε το κόστος των μνημών.

Oρίζοντας τώρα το μέγεθος των μνημών ως L1,L2, προκύπτει: _**MemCost = L1*Pl1 + L2*Pl2**_

Ωστόσο το κόστος σχετίζεται και με το associativity των μνημών, όπως αναφέρθηκα προηγουμένως. Για αυτό το λόγο θα πρέπει να προσαρμοστεί κι αυτό στο κόστος μας, ως _**avl1, avl2.**_

Τότε έχουμε: _**AssocCost = AssocCost = (SL1/8)*PL1*avL1 + (SL2/8)*PL2*avL2**_,(όπου το 8 αφορά το μέγεθος των μπλοκ μνήμης).

Προκύπτει επομένως το συνολικό κόστος: _**ΤotalCost = MemCost + AssocCost**_

Στη συνάρτηση μας ωστόσο θα πρέπει να συμπεριλάβουμε και το CPI, δηλαδή την απόδοση του συστήματος.

Τελικά η συνάρτηση/δείκτης IND, Θα έχει τη μορφή _**IND = TotalCost - CPI**_

Παρακάτω παρουσιάζονται δύο διαγράμματα που αναδεικνύουν την εφαρμογή της συνάρτησης κόστους-αποδοτικότητας στα benchmarks του specsjeng του 2ου Μέρους.


 ![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/78922521_467054267524589_3714794016915587072_n.png)
 
 ![](https://github.com/adelizon/8479-8256-LAB1/blob/master/Lab2/Graphs/79286912_469703587020694_455081699458416640_n.png)
 
 Στο πρώτο διάγραμμα παρουσιάζεται η σχέση κόστους παραγωγικότητας για τις 10 προσομοιώσεις στον specsjeng. Από την υλοποίηση της συνάρτησης αντιλαμβανόμαστε πως στόχος είναι η ελαχιστοποίηση της συνάρτησης. Συνεπώς η πιο συμφέρουσες επιλογές είναι η έκτη και η έβδομη. (_Όπως ειπώθηκε φυσικά, αυτό έχει να κάνει και με τις απαιτήσεις που υπάρχουν για το σύστημα προς υλοποίηση_)

Στο δεύτερο διάγραμμα βλέπουμε τα CPI συναρτήσει του κόστους.
 

## Πηγές
 [Cache Memory](https://superuser.com/questions/808830/why-is-cache-memory-so-expensive)
 
 [dCahce & iCache](http://www.cim.mcgill.ca/~langer/273/18-notes.pdf)
 
 [l1Cache miss cost](https://stackoverflow.com/questions/1126529/what-is-the-cost-of-an-l1-cache-miss)
